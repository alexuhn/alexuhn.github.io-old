---
title: "[혼자 공부하는 컴퓨터구조+운영체제]06장 메모리와 캐시 메모리"
excerpt: "RAM의 특징과 종류, 물리 주소와 논리 주소, 캐시 메모리에 대하여"
categories:
  - book_notes
tags:
  - 혼자 공부하는 컴퓨터구조+운영체제
---

# 06-1 RAM의 특징과 종류

주기억장치는 크게 RAM과 ROM으로 나뉘며, 메모리는 일반적으로 RAM을 지칭한다.

## RAM의 특징

- 실행할 프로그램의 명령어와 데이터 저장
- 휘발성 저장 장치(volatile memory) ⇒ 실행할 대상 저장
  - 전원을 끄면 저장된 내용이 사라짐
  - 보조 기억장치는 비휘발성 저장장치 ⇒ 보관할 대상 저장

## RAM의 용량과 성능

- RAM의 용량이 작은 경우
  - 실행하고자 하는 프로그램을 보조기억장치에서 계속 가져와야 하므로 오랜 시간 소모
- RAM의 용량이 큰 경우
  - 많은 데이터를 미리 RAM에 저장할 수 있기 때문에 많은 프로그램을 동시에 빠르게 실행 가능
  - 용량이 필요 이상 크다고 그에 비례해 속도가 점점 더 빨라지지는 않는다.

## RAM의 종류

### DRAM

- Dynamic RAM
- 저장된 데이터가 동적으로 사라지는 RAM
  - 데이터의 소멸을 막기 위해 일정 주기로 데이터를 다시 저장 필요
- 소비 전력이 낮고, 저렴하고, 집적도가 높음 ⇒ 대용량 설계 용이
- 일반적으로 **주기억장치(RAM)**은 DRAM을 사용

### SRAM

- Static RAM
- 저장된 데이터가 변하지 않는 RAM
  - 주기적으로 데이터를 재활성화할 필요 없음
  - RAM이므로 전원이 꺼지면 데이터가 사라지는 건 마찬가지
- DRAM보다 빠름
- 소비 전력이 크고, 비싸며, 집적도가 낮음
- 대용량일 필요가 없지만 빨라야 하는 저장 장치인 **캐시 메모리**에 사용

### SDRAM

- Synchronous Dynamic RAM
- 클럭 신호와 동기화된 DRAM
- 클럭에 맞춰 동작하고, 클럭 타이밍에 맞춰 CPU와 정보를 주고받음

### DDR SDRAM

- Double Data Rate SDRAM
- 대역폭을 넓혀 속도를 빠르게 만든 SDRAM
  - 대역폭(data rate): 데이터를 주고받는 통로의 너비
- SDR SDRAM(Single Data Rate SDRAM)보다 대역폭이 두 배 넓음<br>
  ⇒ 한 클럭당 두 번씩 CPU와 정보를 주고받을 수 있음<br>
  ⇒ 전송 속도가 두 배가량 빠름
- DDR2 SDRAM: DDR SDRAM보다 대역폭이 두 배 넓은, SDR SDRAM보다는 네 배 넓은 SDRAM<br>
  DDR3 SDRAM: SDR SDRAM보다 대역폭이 여덟 배 넓은 SDRAM<br>
  DDR4 SDRAM: SDR SDRAM보다 대역폭이 열여섯 배 넓은 SDRAM

# 06-2 메모리의 주소 공간

## 물리 주소와 논리 주소

- 물리 주소: 정보가 실제로 저장된 메모리 하드웨어 상의 주소
- 논리 주소: 실행 중인 프로그램에 부여된, CPU와 프로그램이 사용하는 0번지부터 시작되는 주소
  - 프로그램은 모두 0번지부터 시작하는 자신만의 논리 주소를 가지고 있음

### 메모리 관리 장치

- Memory Management Unit, MMU
- 논리 주소를 물리 주소로 변환하는 장치
- CPU와 주소 버스 사이에 위치
- **CPU가 발생시킨 논리 주소**에 **베이스 레지스터** 값을 더해 논리 주소를 물리 주소로 변환
  - 베이스 레지스터: 프로그램의 첫 물리 주소
  - 논리 주소: 프로그램 시작점으로부터 떨어진 거리

## 메모리 보호 기법

### 한계 레지스터(limit register)

- **논리 주소의 최대 크기**를 저장
  - 베이스 레지스터값 ≤ 프로그램의 물리 주소 범위 < 베이스 레지스터값 + 한계 레지스터값
- 논리 주소 범위를 벗어나는 명령어 실행 방지
  - CPU가 접근하는 논리 주소는 한계 레지스터가 저장한 값보다 클 수 없다.
  - 한계 레지스터보다 높은 주솟값에 접근 ⇒ 프로그램 범위 밖의 메모리 공간에 접근
- 실행 중인 프로그램이 독립적인 실행 공간을 확보하고, 다른 프로그램이 침범하지 않도록 방지
- 메모리에 접근하기 전에 CPU는 항상 논리 주소가 한계 레지스터보다 작은지 검사
  - 한계 레지스터보다 작지 않다면 인터럽트(트랩) 발생

# 06-3 캐시 메모리

## 저장 장치 계층 구조

- 저장 장치의 명제
  1. CPU와 가까울수록 저장 장치는 빠르다.
  2. 속도가 빠른 저장 장치는 용량이 작고 비싸다.
- 저장 장치 계층 구조(memory hierarchy)
  - CPU에 얼마나 가까운가를 기준으로 저장 장치를 계층적으로 나타낸 것

    | 계층         | 속도 | 용량 | 가격 |
    | ------------ | ---- | ---- | ---- |
    | 레지스터     | 빠름 | 작음 | 비쌈 |
    | 캐시 메모리  | ↑    | ↑    | ↑    |
    | 메모리       | ↓    | ↓    | ↓    |
    | 보조기억장치 | 느림 | 큼   | 저렴 |

## 캐시 메모리

- CPU와 메모리 사이에 위치
- 레지스터보다 용량이 크고, 메모리보다 빠른 SRAM 기반의 저장 장치
- CPU가 사용할 데이터의 일부를 미리 캐시 메모리에 저장
  ⇒ **CPU 연산 속도와 메모리 접근 속도의 차이를 줄일 수 있다.**
- L1 캐시, L2 캐시, L3 캐시
  - CPU(코어)에 가까운 순서대로 L1 캐시, L2 캐시, L3 캐시로 구분
  - 일반적으로 L1 캐시, L2 캐시는 코어 내부, L3 캐시는 코어 외부에 존재
  - L1-L2-L3 순으로 용량이 크고, 속도가 느리며, 가격이 저렴
  - CPU가 메모리 내의 데이터를 가져올 때 L1-L2-L3 순으로 데이터를 검색
  - 멀티 코어 프로세서에서 일반적으로 L1 캐시, L2 캐시는 코어마다 고유한 캐시 메모리로 할당, L3 캐시는 여러 코어가 공유하는 형태로 사용
- 분리형 캐시(split cache)
  - L1 캐시를 명령어만 저장하는 L1I 캐시, 데이터만 저장하는 L1D 캐시로 분리
  - L1 캐시의 접근 속도를 빠르게 하기 위함

## 참조 지역성 원리

### 캐시 적중률

캐시 메모리는 CPU가 사용할 법한 데이터를 예측하여 저장한다.

- 캐시 히트(cache hit): 캐시 메모리가 알맞은 예측을 하여 CPU가 캐시 메모리 내 데이터를 활용하는 경우
- 캐시 미스(cache miss): 캐시 메모리가 틀린 예측을 하여 CPU가 메모리에서 데이터를 직접 가져와야 하는 경우
  - 자주 발생할 시 성능 저하
- 캐시 적중률(cache hit ratio) = 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)
  - 캐시 적중률이 높으면 CPU의 메모리 접근 횟수를 줄일 수 있다.
  - 일반적으로 사용하는 컴퓨터는 85~95% 이상의 캐시 적중률을 갖는다.

### 참조 지역성 원리

캐시 메모리는 참조 지역성의 원리에 따라 메모리로 가져올 데이터를 결정한다.

1. CPU가 최근에 접근했던 메모리 공간에 다시 접근하려는 경향 ⇒ 시간 지역성(temporal locality)
   1. 예) 변수의 경우 CPU는 여러 번 접근하여 변수를 사용한다.
2. CPU가 접근한 메모리 공간 근처에 다시 접근하려는 경향 ⇒ 공간 지역성(spatial locality)
   1. 예) 관련 있는 데이터들은 보통 한데 모여있다.
